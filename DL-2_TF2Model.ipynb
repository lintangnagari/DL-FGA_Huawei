{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2.2 PROCEDURE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 32)]              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,442\n",
      "Trainable params: 2,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "#Use the output of the previous layer as the input of the next layer.\n",
    "x = tf.keras.Input(shape=(32,))\n",
    "h1 = layers.Dense(32, activation='relu')(x)\n",
    "h2 = layers.Dense(32, activation='relu')(h1)\n",
    "y = layers.Dense(10, activation='softmax')(h2)\n",
    "model_sample_2 = tf.keras.models.Model(x, y)\n",
    "\n",
    "#Print model information.\n",
    "model_sample_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x1d2d480c610>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a fully connected layer that contains 32 neurons. Set the activation function to sigmoid.\n",
    "#The activation parameter can be set to a function name string, for example, sigmoid or a function object, for example, tf.sigmoid. layers.Dense(32, activation='sigmoid') layers.Dense(32, activation=tf.sigmoid)\n",
    "\n",
    "#Set kernel_initializer\n",
    "layers.Dense(32, kernel_initializer=tf.keras.initializers.he_normal)\n",
    "\n",
    "#Set kernel_regularizer to L2 regularization\n",
    "layers.Dense(32, kernel_regularizer=tf.keras.regularizers.l2(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.convolutional.conv2d.Conv2D at 0x1d2d4868d60>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers.Conv2D(64,[1,1],2,padding='same',activation=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.pooling.max_pooling2d.MaxPooling2D at 0x1d2b47cf340>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers.MaxPooling2D(pool_size=(2,2),strides=(2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.1], [0.2], [0.3]]]\n",
      "1/1 [==============================] - 0s 403ms/step\n",
      "output when return_sequences is set to True [[[-0.00352525]\n",
      "  [-0.0088949 ]\n",
      "  [-0.01491457]]]\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "output when return_sequences is set to False [[0.00736878]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = tf.keras.Input(shape=(3, 1))\n",
    "lstm = layers.LSTM(1, return_sequences=True)(inputs)\n",
    "model_lstm_1 = tf.keras.models.Model(inputs=inputs, outputs=lstm)\n",
    "inputs = tf.keras.Input(shape=(3, 1))\n",
    "lstm = layers.LSTM(1, return_sequences=False)(inputs)\n",
    "model_lstm_2 = tf.keras.models.Model(inputs=inputs, outputs=lstm)\n",
    "\n",
    "#Sequences t1, t2, and t3\n",
    "data = [[[0.1], \n",
    "         [0.2], \n",
    "         [0.3]]]\n",
    "\n",
    "print(data)\n",
    "print(\"output when return_sequences is set to True\",model_lstm_1.predict(data))\n",
    "print(\"output when return_sequences is set to False\",model_lstm_2.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.layers.LSTM(16, return_sequences=True)\n",
    "\n",
    "#LSTMCell\n",
    "x = tf.keras.Input((None, 3))\n",
    "y = layers.RNN(layers.LSTMCell(16))(x)\n",
    "model_lstm_3= tf.keras.Model(x, y)\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine the optimizer (optimizer), loss function (loss), and model evaluation method (metrics).\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss=tf.keras.losses.categorical_crossentropy,\n",
    "              metrics=[tf.keras.metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 1s 22ms/step - loss: 12.1642 - categorical_accuracy: 0.0880 - val_loss: 12.0438 - val_categorical_accuracy: 0.0950\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 12.1631 - categorical_accuracy: 0.0880 - val_loss: 12.0429 - val_categorical_accuracy: 0.0950\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 12.1630 - categorical_accuracy: 0.0880 - val_loss: 12.0430 - val_categorical_accuracy: 0.0950\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 12.1625 - categorical_accuracy: 0.0870 - val_loss: 12.0422 - val_categorical_accuracy: 0.0950\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 12.1619 - categorical_accuracy: 0.0870 - val_loss: 12.0414 - val_categorical_accuracy: 0.0950\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 12.1616 - categorical_accuracy: 0.0870 - val_loss: 12.0417 - val_categorical_accuracy: 0.0950\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 12.1612 - categorical_accuracy: 0.0870 - val_loss: 12.0407 - val_categorical_accuracy: 0.0950\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 12.1605 - categorical_accuracy: 0.0880 - val_loss: 12.0407 - val_categorical_accuracy: 0.0950\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 12.1606 - categorical_accuracy: 0.0880 - val_loss: 12.0407 - val_categorical_accuracy: 0.0950\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 12.1603 - categorical_accuracy: 0.0880 - val_loss: 12.0400 - val_categorical_accuracy: 0.0950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d39f2cea60>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_x = np.random.random((1000, 36))\n",
    "train_y = np.random.random((1000, 10))\n",
    "val_x = np.random.random((200, 36))\n",
    "val_y = np.random.random((200, 10))\n",
    "model.fit(train_x, train_y, epochs=10, batch_size=100,\n",
    "          validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 8ms/step - loss: 12.1350 - categorical_accuracy: 0.0896 - val_loss: 11.8892 - val_categorical_accuracy: 0.0938\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 12.1537 - categorical_accuracy: 0.0919 - val_loss: 11.8889 - val_categorical_accuracy: 0.0938\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 12.1586 - categorical_accuracy: 0.0865 - val_loss: 11.8879 - val_categorical_accuracy: 0.0938\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 12.1602 - categorical_accuracy: 0.0865 - val_loss: 11.8863 - val_categorical_accuracy: 0.0938\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 12.1214 - categorical_accuracy: 0.0887 - val_loss: 11.8845 - val_categorical_accuracy: 0.0938\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 12.1396 - categorical_accuracy: 0.0908 - val_loss: 11.8830 - val_categorical_accuracy: 0.0938\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 12.1550 - categorical_accuracy: 0.0876 - val_loss: 11.8816 - val_categorical_accuracy: 0.0938\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 12.1670 - categorical_accuracy: 0.0919 - val_loss: 11.8804 - val_categorical_accuracy: 0.0938\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 12.1377 - categorical_accuracy: 0.0855 - val_loss: 11.8792 - val_categorical_accuracy: 0.0938\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 12.1796 - categorical_accuracy: 0.0897 - val_loss: 11.8776 - val_categorical_accuracy: 0.0938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d2cd562610>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
    "dataset = dataset.batch(32)\n",
    "dataset = dataset.repeat()\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_x, val_y))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "val_dataset = val_dataset.repeat()\n",
    "model.fit(dataset, epochs=10, steps_per_epoch=30,\n",
    "          validation_data=val_dataset, validation_steps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 12.4010 - categorical_accuracy: 0.0930 - val_loss: 12.1581 - val_categorical_accuracy: 0.0900 - lr: 0.1000\n",
      "0.1\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 12.4910 - categorical_accuracy: 0.0900 - val_loss: 12.3064 - val_categorical_accuracy: 0.0900 - lr: 0.1000\n",
      "0.1\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 12.4218 - categorical_accuracy: 0.0920 - val_loss: 12.0491 - val_categorical_accuracy: 0.1050 - lr: 0.1000\n",
      "0.01\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 12.1079 - categorical_accuracy: 0.0890 - val_loss: 12.0334 - val_categorical_accuracy: 0.1150 - lr: 0.0100\n",
      "0.01\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 12.1342 - categorical_accuracy: 0.0920 - val_loss: 11.9379 - val_categorical_accuracy: 0.0950 - lr: 0.0100\n",
      "0.01\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 12.1203 - categorical_accuracy: 0.0910 - val_loss: 11.9310 - val_categorical_accuracy: 0.1050 - lr: 0.0100\n",
      "0.001\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 12.0478 - categorical_accuracy: 0.0900 - val_loss: 11.9392 - val_categorical_accuracy: 0.1050 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d3a7bdfd90>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set hyperparameters.\n",
    "Epochs = 10\n",
    "#Define a function for dynamically setting the learning rate.\n",
    "def lr_Scheduler(epoch):\n",
    "   if epoch > 0.9 * Epochs:\n",
    "      lr = 0.0001\n",
    "   elif epoch > 0.5 * Epochs:\n",
    "      lr = 0.001\n",
    "   elif epoch > 0.25 * Epochs:\n",
    "      lr = 0.01\n",
    "   else:\n",
    "      lr = 0.1\n",
    "   \n",
    "   print(lr)\n",
    "   return lr\n",
    "\n",
    "callbacks = [\n",
    "#Early stopping:\n",
    "   tf.keras.callbacks.EarlyStopping(\n",
    "#Metric for determining whether the model performance has no further improvement\n",
    "   monitor='val_loss',\n",
    "#Threshold for determining whether the model performance has no further improvement\n",
    "   min_delta=1e-2,\n",
    "#Number of epochs in which the model performance has no further improvement\n",
    "   patience=2),\n",
    "#Periodically save models.\n",
    "   tf.keras.callbacks.ModelCheckpoint(\n",
    "#Model path\n",
    "   filepath='testmodel_{epoch}.h5',\n",
    "#Whether to save the optimal model.\n",
    "   save_best_only=True,\n",
    "#Monitored metric\n",
    "   monitor='val_loss'),\n",
    "#Dynamically change the learning rate.\n",
    "   tf.keras.callbacks.LearningRateScheduler(lr_Scheduler),\n",
    "#Use TensorBoard.\n",
    "   tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "]\n",
    "\n",
    "model.fit(train_x, train_y, batch_size=16, epochs=Epochs,\n",
    "callbacks=callbacks, validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 12.3695 - categorical_accuracy: 0.1220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[12.369544982910156, 0.12200000137090683]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model evaluation\n",
    "test_x = np.random.random((1000, 36))\n",
    "test_y = np.random.random((1000, 10))\n",
    "model.evaluate(test_x, test_y, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step\n",
      "[[0.06471244 0.06549323 0.09057109 ... 0.11202481 0.02795932 0.08894405]\n",
      " [0.07243478 0.07211496 0.11079419 ... 0.2119318  0.02814083 0.08649752]\n",
      " [0.08891644 0.05908849 0.14934845 ... 0.24642192 0.06437134 0.08014077]\n",
      " ...\n",
      " [0.06288819 0.17370349 0.07604307 ... 0.16760048 0.06406596 0.04978967]\n",
      " [0.0921402  0.06780529 0.16550049 ... 0.15973444 0.0262548  0.06238133]\n",
      " [0.0523982  0.06769045 0.10962795 ... 0.21516578 0.08620305 0.05055104]]\n"
     ]
    }
   ],
   "source": [
    "#Model prediction\n",
    "pre_x = np.random.random((10, 36))\n",
    "result = model.predict(test_x,)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Save models.\n",
    "model.save('./model/the_save_model.h5')\n",
    "\n",
    "#Import models.\n",
    "new_model = tf.keras.models.load_model('./model/the_save_model.h5')\n",
    "new_prediction = new_model.predict(test_x)\n",
    "\n",
    "#np.testing.assert_allclose: determines whether the similarity between two objects exceeds the specified tolerance. If yes, the system displays an exception. :\n",
    "#atol: specified tolerance\n",
    "np.testing.assert_allclose(result, new_prediction, atol=1e-6) #Prediction results are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./model/model_weights')\n",
    "model.save_weights('./model/model_weights.h5')\n",
    "\n",
    "#Load the weights.\n",
    "model.load_weights('./model/model_weights')\n",
    "model.load_weights('./model/model_weights.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MS20_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
